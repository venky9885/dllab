# -*- coding: utf-8 -*-
"""02 Multiclass Classifier_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S43rFyf3NIkUp7b-oO3v5_J1jIpKVpMC
"""



"""# You want to train a multiclass classifier neural network.

# Use Keras to construct a feedforward neural network with an output layer with softmax ctivation functions

First, our data is 11,228 Reuters newswires.
Each newswire is categorized into 46 topics. 
We prepared our feature data by converting the newswires into 5,000 binary features (denoting the presence of a certain word in the newswires). 
We prepared the target data by one-hot encoding it so that we obtain a target matrix denoting which of the 46 classes an observation belongs to.

Second, we increased the number of units in each of the hidden layers to help the neural network represent the more complex relationship between the 46 classes.

Third, since this is a multiclass classification problem, we used an output layer with 46 units (one per class) containing a softmax activation function. 
The softmax activation function will return an array of 46 values summing to 1. 
These 46 values represent an observationâ€™s probability of being a member of each of the 46 classes.

Fourth, we used a loss function suited to multiclass classification, the categorical cross-entropy loss function, categorical_crossentropy.
"""

# Load libraries
import numpy as np
from keras.datasets import reuters
from keras.utils.np_utils import to_categorical
from keras.preprocessing.text import Tokenizer
from keras import models
from keras import layers

# Set random seed
np.random.seed(0)

# Set the number of features we want
number_of_features = 5000

# Load feature and target data
data = reuters.load_data(num_words=number_of_features)
(data_train, target_vector_train), (data_test, target_vector_test) = data

# Convert feature data to a one-hot encoded feature matrix
tokenizer = Tokenizer(num_words=number_of_features)
features_train = tokenizer.sequences_to_matrix(data_train, mode="binary")
features_test = tokenizer.sequences_to_matrix(data_test, mode="binary")

# One-hot encode target vector to create a target matrix
target_train = to_categorical(target_vector_train)
target_test = to_categorical(target_vector_test)

target_vector_test

target_test

# Start neural network
network = models.Sequential()

# Add fully connected layer with a ReLU activation function
network.add(layers.Dense(units=100,activation="relu",
input_shape=(number_of_features,)))

# Add fully connected layer with a ReLU activation function
network.add(layers.Dense(units=100, activation="relu"))

# Add fully connected layer with a softmax activation function
network.add(layers.Dense(units=46, activation="softmax"))

# Compile neural network
network.compile(loss="categorical_crossentropy", # Cross-entropy
optimizer="rmsprop",                            # Root Mean Square Propagation
metrics=["accuracy"])                           # Accuracy performance metric

# Train neural network
history = network.fit(features_train, # Features
target_train, # Target
epochs=3, # Three epochs
verbose=0, # No output
batch_size=100, # Number of observations per batch
validation_data=(features_test, target_test)) # Test data

# Train neural network
history = network.fit(features_train, target_train, epochs=3, verbose=1, batch_size=100, validation_data=(features_test, target_test))

features_train
features_test